---
title: 'Proyecto semestral: Hito 2'
author: Nicolás Herrera, Yesenia Marulanda, Franco Migliorelli, Samuel Sánchez, Sebastián
  Urbina
date: "Diciembre 2020"
output:
  html_document:
    number_sections: yes
    theme: spacelab
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---


# Motivacion:

Twitter es una de las redes sociales más utilizadas para comentar, compartir o debatir temas de actualidad y tendencias. El primer trimestre de 2020 tuvo un aumento de un 23% en comentarios diarios con respecto al mismo periodo de tiempo del año 2019 [1], siendo una de sus principales causas la pandemia del COVID-19. 
Dado este contexto, es que analizar datos de Twitter es interesante, pues además de que es posible obtener información en tiempo real de sucesos importantes, como el caso de la pandemia, se pueden aplicar métodos de minería de datos para manipular grandes volúmenes de información, analizándola y obteniendo en muchas ocasiones conclusiones no triviales acerca de esta.  
En el presente estudio se explorarán entonces Tweets relacionados con coronavirus en un intervalo de tiempo acotado, desde la perspectiva de los sentimientos y relacionándolos con el contexto país desde donde se emiten; buscando establecer si este ultimo influencia la percepción de las personas acerca de la pandemia.
Es importante aclarar que se eligió el procesamiento del lenguaje natural como la herramienta a utilizar debido a la indiscutible importancia que supone identificar la subjetividad y el grado de valoración de miles de personas en cada instante para empresas, organizaciones, gobiernos y la población misma.

Dicho lo anterior, los puntos claves a analizar en el desarrollo del proyecto son:

- Identificar cómo se relaciona el sentimiento identificado con el contexto país (según mayor o menor presencia del sentimiento).
- Identificar palabras que son clave a la hora de categorizar el sentimiento.
- Establecer algoritmos para predecir sentimientos de forma sistematizada.
- Entrenar modelos de clasificaciòn en base a tweets usando un dataset de entrenamiento y un dataset de evaluacion.


# Descripción de base de datos

La base  de datos, extraída desde la plataforma *Kaggle*[2], esta compuesta en principio por 44.955 tweets  relacionados con el tema COVID 19 y que fueron publicados desde el 2 de marzo al 14 de abril de 2020. Además de encontrarse el texto publicado se encuentran en la base de datos los atributos de fecha exacta de publicación, ubicación desde la cual se realizla publicación, un identificador para el usuario y la asignación de sentimiento para cada tweet. La asignación de sentimiento a cada Tweet fue realizada de forma manual por el propietario de la base de datos. Esta variable de sentimiento sería un punto de comparación para un posible modelo de clasifiación de los sentimientos de los tweets.


# Exploración de datos
El objetivo de esta sección es describir la base de datos seleccionada, mostrando estadísticas de resumen, gráficos relevantes para la descripción y un breve análisis sobre estos.

El primer paso consiste en cargar todas las librerías que se utilizarán en este trabajo, las cuales permiten realizar gráficos y trabajar con los datos de una forma más simple y eficiente.
```{r, message = F, warning=F}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(tidytext)
library(stopwords)
library(wordcloud)
library(wordcloud2)
library(stringr)
```

A continuación se procece a cargar la base de datos para poder realizar el análisis respectivo. Además se incluye un dataframe con datos del covid para visualizar ciertas relaciones entre sentimientos y casos nuevos.

```{r}
train  <- read.csv("data/Corona_NLP_train.csv", encoding="Latin-1")
test <- read.csv("data/Corona_NLP_test.csv", encoding="Latin-1")
df <- rbind(train,test)
covid <- read.csv("data/covid-data.csv", encoding = "UTF-8") #datos del covid 
covid$date <- as.Date(covid$date) #cambiamos a date las fechas de covid
```

Tal y como se mencionó anteriormente, esta base de datos contiene 6 columnas y 44.955 filas de datos. Para poder tener una referencia de cómo son estos campos, a continuación se puede observar una vista previa de las primeras filas del set de datos.

```{r}
head(df)
```

Para poder trabajar con los datos es necesario convertir algunos formatos de las variables, en particular en este caso, se procede a transformar las variables "TweetAt" a un formato de fecha, dado que corresponde al momento en donde se realizó el tweet, y la variable "OriginalTweet" que corresponde al contenido del tweet realizado.

```{r}
df$TweetAt <- as.Date(df$TweetAt, format="%d-%m-%y")
df$OriginalTweet <- as.character(df$OriginalTweet)
```

Los formatos de cada variable del set de datos son mostrados a continuación:
```{r}
str(df)
```

Además, es importante mencionar con qué periodos se estará trabajando, por lo que el resultado de la siguiente línea de código arroja la fecha mínima y máxima del set de datos, siendo el 2 de marzo de 2020 y el 14 de abril de 2020 respectivamente.

```{r}
summary(df$TweetAt)
```

Para ver cómo están distribuidos los tweets en el tiempo, a continuación se realiza y muestra un histograma con las distribuciones de las fechas de los tweets realizados y registrados en esta base de datos.

```{r}
ggplot(data=df, aes(x=TweetAt)) + geom_histogram(position="identity", bins=30) +
  labs(title = "Distribución de las fechas de tweets", x = "fecha de publicación",
       y = "número de tweets") + theme_bw()
```

Un comportamiento particular de los datos es que a finales de marzo la cantidad de tweets registrados disminiye considerablemente llegando a ser nulo, mientras que la mayor cantidad de tweets se encuentra concentrada durante la tercera semana de marzo y la segunda semana de abril.

Un campo importante que posee esta base de datos es la columna "Sentiment", la cual representa el sentimiento asociado al tweet registrado. A continuación se presenta la cantidad de tweets segun tipo de sentimiento ("Extremely Negative", "Extremely Postive", "Negative", "Neutral", "Positive") durante el periodo registrado en el set de datos.
```{r}
tweets_mes_dia <- df %>% mutate(mes_dia = format(TweetAt, "%m-%d"))
tweets_mes_dia %>% group_by(Sentiment, mes_dia) %>% summarise(n = n()) %>%
  ggplot(aes(x = mes_dia, y = n, color = Sentiment)) +
  geom_line(aes(group = Sentiment)) +
  labs(title = "Número de tweets publicados", x = "fecha de publicación",
       y = "número de tweets") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, size = 6),
        legend.position = "bottom")
```

Se puede observar en este último gráfico que en general aquellos sentimientos que prevalecen son los de "Positive" y "Negative". Por otro lado, todos los tipos de sentimientos registrados tienen un comportamiento similar a lo largo del tiempo. Mientras que el sentimiento  menos registrados en el tiempo  corresponde al de "Extremely Negative", lo cual es interesante dado el contexto de la base de datos, en donde se esperaría que hubiese una mayor cantidad de tweets asociado a un sentimiento negativo o extramademente negativo.


Sería interesante observar la cantidad de casos nuevos en relación a los sentimientos en las fechas, lo siguiente realiza lo mencionado.


```{r}
#filtramos las fechas para que se ajusten a los datos de los tweets y seleccionamos los nuevos casos mundiales
covid_word <- covid[covid$date >= min(df$TweetAt) & covid$date <= max(df$TweetAt) & covid$location == "World",]
#seleccionamos sólo la fecha y nuevos casos
covid_new_cases <- covid_word %>% select(date, new_cases)

#Creamos una nueva columna en formado "mes-dia" para graficar 
covid_new_cases <- covid_new_cases %>% mutate(mes_dia = format(date, "%m-%d")) %>% select(-c(1))
tw_mes_dia <- tweets_mes_dia %>% group_by(Sentiment, mes_dia) %>% summarise(n = n())
#Unimos los nuevos casos con el df de tweets
tw <- merge(tw_mes_dia, covid_new_cases, by = "mes_dia")

ggplot(data = tw, aes( x = mes_dia)) + 
  geom_line(aes( y = n, color = Sentiment, group = Sentiment)) + 
  geom_line(aes( y = new_cases/100, group = Sentiment)) +
  scale_y_continuous(name = "Cantidad Tweets", sec.axis = sec_axis(~.*100, name = "Casos Nuevos"))+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom") + 
  labs(x = "Fecha", title = "Evolución Sentimientos y Casos Nuevos COVID en el Mundo") + 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom")
#ggsave(plot = last_plot(), dpi = 300, filename = "evol_sent_casos_covid.pdf")
```
En generar se puede observar que la tendencia de casos nuevos es bastante clara en los meses de abril y marzo, sin embargo no se aprecia alguna relación con los sentimientos. Esto puede deberse a que la recolección de tweets fue intermitente y por tanto no puede representar de manera efectiva las emociones etiquetadas manualmente de forma global.


```{r}
states <- "AL|AK|AZ|AR|CA|CO|CT|DE|FL|GA|HI|ID|IL|IN|IA|KS|KY|LA|ME|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC|ND|OH|OK|OR|PA|RI|SC|SD|TN|TX|UT|VT|VA|WA|WV|WI|WY|Alabama|Alaska|Arizona|Arkansas|California|Colorado|Connecticut|Delaware|Florida|Georgia|Hawaii|Idaho|Illinois|Indiana|Iowa|Kansas|Kentucky|Louisiana|Maine|Maryland|Massachusetts|Michigan|Minnesota|Mississippi|Missouri|Montana|Nebraska|Nevada|New Hampshire|New Jersey|New Mexico|NewYork|North Carolina|North Dakota|Ohio|Oklahoma|Oregon|Pennsylvania|Rhode Island|South Carolina|South Dakota|Tennessee|Texas|Utah|Vermont|Virginia|Washington|West Virginia|Wisconsin|Wyoming|USA|United States|Estados Unidos|EEUU"
tweets_usa <- df %>% filter(grepl(states, Location)) %>% filter(!grepl("INDIA|india|India|London|uk|UK|london|england|England|LONDON", Location)) 

tweets_uk <- df %>% filter(grepl("London|uk|UK|london|england|England|LONDON",Location))
tweets_india <- df %>% filter(grepl("india|India|INDIA", Location)) %>% filter(!grepl("Indiana|indiana",Location))
```

```{r}
covid_usa <- covid[covid$date >= min(df$TweetAt) & covid$date <= max(df$TweetAt) & covid$location == "United States",]
covid_usa <- covid_usa %>% select(date, new_cases)

covid_usa <- covid_usa %>% mutate(mes_dia = format(date, "%m-%d")) %>% select(-c(1))


tweets_usa$TweetAt <- as.Date(tweets_usa$TweetAt, format="%d-%m-%y")
tweets_mes_dia_usa <- tweets_usa %>% mutate(mes_dia = format(TweetAt, "%m-%d"))

tweets_mes_dia_usa <- tweets_mes_dia_usa %>% group_by(Sentiment, mes_dia) %>% summarise(n = n())
###
tweets_mes_dia_usa <- merge(tweets_mes_dia_usa, covid_usa, by = "mes_dia")


ggplot(data = tweets_mes_dia_usa, aes( x = mes_dia)) + 
  geom_line(aes( y = n, color = Sentiment, group = Sentiment)) + 
  geom_line(aes( y = new_cases/100, group = Sentiment)) +
  scale_y_continuous(name = "Cantidad Tweets", sec.axis = sec_axis(~.*100, name = "Casos Nuevos"))+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom") + 
  labs(x = "Fecha", title = "Evolución Sentimientos y Casos Nuevos COVID en USA") + 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom")

```

Luego al realizar el mismo análisis con respecto a los casos nuevos en Estados Unidos, el país con más tweets en el dataframe, no se observar patrones de relación respecto a los sentimientos. Asimismo se mantiene la prevalencia de sentimientos positivos a lo largo del tiempo.

```{r}
covid_uk <- covid[covid$date >= min(df$TweetAt) & covid$date <= max(df$TweetAt) & covid$location == "United Kingdom",]
covid_uk <- covid_uk %>% select(date, new_cases)

covid_uk <- covid_uk %>% mutate(mes_dia = format(date, "%m-%d")) %>% select(-c(1))


tweets_uk$TweetAt <- as.Date(tweets_uk$TweetAt, format="%d-%m-%y")
tweets_mes_dia_uk <- tweets_uk %>% mutate(mes_dia = format(TweetAt, "%m-%d"))

tweets_mes_dia_uk <- tweets_mes_dia_uk %>% group_by(Sentiment, mes_dia) %>% summarise(n = n())
###
tweets_mes_dia_uk <- merge(tweets_mes_dia_uk, covid_uk, by = "mes_dia")


ggplot(data = tweets_mes_dia_uk, aes( x = mes_dia)) + 
  geom_line(aes( y = n, color = Sentiment, group = Sentiment)) + 
  geom_line(aes( y = new_cases/100, group = Sentiment)) +
  scale_y_continuous(name = "Cantidad Tweets", sec.axis = sec_axis(~.*100, name = "Casos Nuevos"))+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom") + 
  labs(x = "Fecha", title = "Evolución Sentimientos y Casos Nuevos COVID en UK") + 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom")
```

Si ahora vemos los casos nuevos y sentimientos del Reino Unido, en general la tendencia de tweets positivos no se mantiene, pues a principios de marzo la cantidad de Tweets negativos supera a los pasitivos, exactamente el 11 de marzo. 


```{r}
#covid <- read.csv("data/covid-data.csv", encoding = "UTF-8") #datos del covid 
covid_india <- covid[covid$date >= min(df$TweetAt) & covid$date <= max(df$TweetAt) & covid$location == "India",]
covid_india <- covid_india %>% select(date, new_cases)

covid_india <- covid_india %>% mutate(mes_dia = format(date, "%m-%d")) %>% select(-c(1))
#Unimos los nuevos casos con el df de tweets

####
tweets_india$TweetAt <- as.Date(tweets_india$TweetAt, format="%d-%m-%y")
tweets_mes_dia_india <- tweets_india %>% mutate(mes_dia = format(TweetAt, "%m-%d"))
tweets_mes_dia_india <- tweets_mes_dia_india %>% group_by(Sentiment, mes_dia) %>% summarise(n = n())
###
tweets_mes_dia_india <- merge(tweets_mes_dia_india, covid_india, by = "mes_dia")

ggplot(data = tweets_mes_dia_india, aes( x = mes_dia)) + 
  geom_line(aes( y = n, color = Sentiment, group = Sentiment)) + 
  geom_line(aes( y = new_cases/100, group = Sentiment)) +
  scale_y_continuous(name = "Cantidad Tweets", sec.axis = sec_axis(~.*100, name = "Casos Nuevos"))+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom") + 
  labs(x = "Fecha", title = "Evolución Sentimientos y Casos Nuevos COVID en India") + 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, size = 10),legend.position = "bottom")

```

En relación con India, el patron de sentimientos a lo largo del tiempo es bastante intermitente, lo que puede deberse en parte a la escasa recolección de Tweets. Sin embargo, no deja de ser interesante que el 20 de marzo existe un pico de contagios negativos. En general no prevalecen los sentimientos positivos como Estados Unidos, lo que no deja de llamar la atención. Aunque hay que tener en consideración que los tweets recolectados de India son pocos. 

En el siguiente gráfico se puede observar la cantidad de tweets por cada tipo de sentimiento durante todo el periodo de observación.
```{r}
# library(tidyverse)
#tweets_sentiment <- df %>% group_by(Sentiment) %>% summarise(n = n())
df %>% ggplot(aes(x = Sentiment)) + geom_bar(stat="count") + coord_flip() + theme_bw()
```

Se observa que tal y como se mencionó anteriormente, los sentimientos que destacan son "Positive" y "Negative", alcanzando un total aproximado de 13000 y 11000 tweets respectivamente. El sentimiento con una menor cantidad de registros es "Extremely Negative", con un aproximado de 6000 tweets. 

Si se comparación la proporción de estos tweets en comparación al total del periodo de observación, se tiene que el porcentaje asociado a cada sentimiento son los siguientes:

```{r}
df %>% group_by(Sentiment) %>% summarise(Proporcion = n()/nrow(df)) %>% arrange(-Proporcion)
```

Es decir, el sentimiento "Positive" representa al 27,5% de los tweets del set de datos, mientras que el 13,5% de los tweets están categorizados bajo el sentimiento "Extremely Negative".Es importante notar que los sentimientos extremos tanto positivo como negativo se presentan en menor proporcion.

Otro punto importante a caracterizar es la locación en donde se emiten los tweets. En la siguiente tabla, se puede observar la cantidad total de tweets registrados para el top 10 de localidades.

```{r}
top_10 <- df %>% group_by(Location) %>% summarise(N=n()/nrow(df)) %>% arrange(-N)
top_10 <- top_10[1:10,]
top_10$N <- round(top_10$N,4)
ggplot(top_10,aes(x=reorder(Location,N), y =N )) + 
  geom_bar(stat="identity") + 
  coord_flip() + 
  labs(x="Pais", y = "Proporción del total de tweets", title="Top-10 locaciones con más tweets") +
  theme_bw() 
```

En este último gráfico se puede observar que un 20% de los tweets no registran alguna locación, lo que se puede atribuir a que dentro de la aplicacion de twitter no todas las personas comparten su ubicacion. Del porcentaje restante, los lugares más comunes son de países como Estados Unidos, Reino Unido e India. Se puede observar tambien que la estandarizacion de las localidades no es la mejor, pues no siempre estan relacionadas a un pais de origen.

Para poder analizar los contenidos de los tweets es necesario realizar una limpieza y normalización de estos. A continuación se crea una función que permite corregir algunos patrones de los textos tales como números, puntuación y espacios en blanco.

```{r}
limpiar_texto <- function(texto){
    # Se convierte todo el texto a minúsculas
    nuevo_texto <- tolower(texto)
    # Eliminación de páginas web (palabras que empiezan por "http." seguidas 
    # de cualquier cosa que no sea un espacio)
    nuevo_texto <- str_replace_all(nuevo_texto,"http\\S*", "")
    # Eliminación de signos de puntuación
    nuevo_texto <- str_replace_all(nuevo_texto,"[[:punct:]]", " ")
    # Eliminación de números
    nuevo_texto <- str_replace_all(nuevo_texto,"[[:digit:]]", " ")
    # Eliminación de espacios en blanco múltiples
    nuevo_texto <- str_replace_all(nuevo_texto,"[\\s]+", " ")
    # Tokenización por palabras individuales
    nuevo_texto <- str_split(nuevo_texto, " ")[[1]]
    # Eliminación de tokens con una longitud < 2
    nuevo_texto <- keep(.x = nuevo_texto, .p = function(x){str_length(x) > 1})
    return(nuevo_texto)
}
```

Para entender como procede esta última función, en la siguiente línea se muestra un ejemplo junto con los resultados de la aplicación de esta, en donde se puede observar que se extrajo cada palabra del objeto *text*.

```{r}
text = "Hola mi nombre es https://www.google.cl. Como. no sé xd6666 ASDA"
limpiar_texto(text)
```

En el siguiente paso, se aplica la función *limpiar_texto* al contenido de los tweets de la base de datos, en donde cada resultado de cada tweet es almacenado en un vector de palabras, por lo que cada tweet tendría asociado uno de estos vectores.

```{r}
tweets <- df %>% mutate(texto_vector = map(.x = OriginalTweet, .f = limpiar_texto))
```
  
```{r}
tweets %>% select(texto_vector) %>% head()
```
```{r}
#Cada valor de la columna texto_vector es un vector con cada palabra del texto
tweets$texto_vector[1]
```

En donde cada valor de la columna texto_vector es un vector con cada palabra del texto
```{r}
#unnest() nos permite realizar una expansión de los vectores de palabras que creamos, esto aumenta la dimension de filas considerablemente
tweets_expand <- tweets %>% select(-OriginalTweet) %>% unnest()
tweets_expand <- tweets_expand %>% rename(word = texto_vector)
head(tweets_expand) 
```
Se utilizan *stopwords* para filtrar algunas palabras propias del inglés (lenguaje dominio de los comentarios) como artículos, pronombres, preposiciones, adverbios e incluso algunos verbos. Palabras que no tienen un significado por sí solas, sino que modifican o acompañan a otras.

```{r}
# "word" %in% vector -> true or false
lista_stopwords <- stopwords("english")
lista_stopwords <- c(lista_stopwords, "amp","can")
```

Luego se representa en un gráfico de barras sobre las 10 palabras más repetidas en los comentarios según el sentimiento asignado al Tweet en el que se encuentran.

```{r}
tweets_expand <- tweets_expand %>% filter(!(word %in% lista_stopwords)) 

tweets_expand %>% group_by(Sentiment, word) %>% 
  count(word) %>% 
  group_by(Sentiment) %>% 
  top_n(10,n) %>% 
  arrange(Sentiment, desc(n)) %>% 
  ggplot(aes(x=reorder(word,n),y=n,fill=Sentiment)) + 
  geom_col() + 
  labs(y = "Frecuencia", x = "Palabras mas repetidas") + 
  coord_flip()
```

Se puede observar que, como era de esperarse, las palabras más comentadas en todas las categorias de sentimiento son las referentes directamente a la pandemia: "covid" y "coronavirus". Se destaca de igual forma la alta popularidad de las palabras "food" y "prices", posiblemente debido al parcial desabastecimiento de productos y la subida de precios producto de la cuarentena.

Un análisis similar se presenta a continuación, pero esta vez en nubes de palabras:

```{r}
#Listas de colores utilizadas en las nubes de palabras
pal_neg <- c("#FC9272", "#FB6A4A", "#EF3B2C", "#CB181D", "#A50F15")
pal_neu <- c("#A1D99B", "#74C476", "#41AB5D", "#238B45", "#006D2C")
pal_pos <- c("#9ECAE1", "#6BAED6", "#4292C6", "#2171B5", "#08519C")

most_frec <- c("covid","coronavirus","supermarket","grocery","store")

top <- 400
```

```{r}
#Palabras más repetidas en comentarios negativos y extremadamente negativos
neg_tweets <- tweets_expand %>% 
  filter(Sentiment == "Negative" | Sentiment == "Extremely Negative") %>%
  count(word)
neg_tweets_top <- neg_tweets%>% 
  arrange(desc(n)) %>%
  top_n(top,n) 


set.seed(1234)
wordcloud(words = neg_tweets_top$word, scale=c(5,0.7), freq = neg_tweets_top$n, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35, colors=pal_neg)
```

```{r}
#Palabras más repetidas en comentarios neutrales
neu_tweets <- tweets_expand %>% 
  filter(Sentiment == "Neutral") %>%
  count(word)
neu_tweets_top <- neu_tweets%>%
  arrange(desc(n)) %>%
  top_n(top,n) 
  

set.seed(1234)
wordcloud(words = neu_tweets_top$word, scale=c(5,0.7), freq = neu_tweets_top$n, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35, colors=pal_neu, fixed.asp = TRUE)
```

```{r}
#Palabra más repetidas en comentarios positivos y extremadamente positivos
pos_tweets <- tweets_expand %>% 
  filter(Sentiment == "Positive" | Sentiment == "Extremely Positive") %>%
  count(word)
pos_tweets_top <- pos_tweets%>% 
  arrange(desc(n)) %>%
  top_n(top,n) 


set.seed(1234)
wordcloud(words = pos_tweets_top$word, scale=c(5,0.7), freq = pos_tweets_top$n, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35, colors=pal_pos, fixed.asp = TRUE)
```

Se puede destacar que el tipo de palabras utilizadas en los 3 contextos de sentimiento (negativo, neutral y positivo) no varía en gran manera, repitiendose típicamente las mismas dentro de las mas populares: "covid", "coronavirus", "supermarket", "food", "prices", "store" y "grocery". Dejando de lado la palabra "covid" las palabras más repetidas se relacionan con el abastecimiento de productos basicos, lo que permite inferir de forma preliminar que este tema fue relevante para los usuarios durante la pandemia (entre marzo y abril).

En base a los datos obtenidos categorizados por sentimiento, puede analizarse su largo promedio, y así ver si existe alguna relación entre esas variables. Para esto se hace uso de los boxplot, con el fin de comparar promedios y distribuciones, y detectar algunos outliers segun el sentimiento. Es importante destacar aquí la presencia de hashtags (#), que suponen una mayor extensión al largo del tweet.
  
```{r}
#Promedio en el largo de tweets por sentimiento.

ggplot(tweets, aes(x=Sentiment, y =str_length(OriginalTweet) ),) + geom_boxplot() + labs(y = "Largo", title= "Distribucion del largo de tweets por sentimiento")

ggsave(plot = last_plot(), width = 10, height = 10, dpi = 300, filename = "boxplot_len_words.png")
```

Se puede observar que el largo de las palabras no parece ser determinante para el valor de sentimiento del comentario en general, pues en promedio todas miden muy parecido: aproximadamente 8 caracteres.

# Mejora Hito 1

A partir de los resultados obtenidos en el Hito 1, se plantearon en su momento las siguientes preguntas/hipótesis. Algunas de ellas ya han sido respondidas, algunas serán evaluadas en el hito 3 y otras serán eliminadas del proyecto según se indica a continuación. 
1.	¿El sentimiento general sobre el COVID-19 varía por la localidad registrada?
A partir del análisis exploratorio de datos se respondió esta pregunta, en el presente hito se procedió a estandarizar los valores de localidad que tenia la base de datos inicial, para de esta manera agrupar los datos de forma mas ordenada, para que los resultados obtenidos permitan una mejor visualización y comprensión de los datos. No es necesario evaluar esta pregunta en el hito 3.
2.	Dada las características del COVID-19 y sus consecuencias, más del 50% de los tweets están asociados a un sentimiento negativo o extremadamente negativo.
Esta pregunta fue respondida para la base de datos inicial en el Hito 1 sin embargo se incorporará nueva información que necesita ser evaluada (set de evaluación).  Se comparan los análisis de sentimiento obtenidos para los dos grupos de información. 
Si hubo alguna variación de sentimiento en estos dos instantes de tiempo.
3.	¿Los sentimientos mayormente expresados en los Tweets tienen relación con el contexto social del lugar desde donde son publicados?
Debido a la orientación que se le dará finalmente al proyecto esta pregunta se encuentra fuera de los alcances, por lo tanto, se eliminará. 
4.	¿Se puede asociar un sentimiento a una palabra dependiendo de las otras palabras que forman el tweet analizado?
No se evaluará debido a la complejidad de las herramientas necesarias para abordar el problema, estas no se encuentran en el contenido del curso.
5.	¿Existe una variacion de comentarios positivos al avanzar los días? ¿Si es así, a qué se debe?
No es posible establecer una razón clara a la cual atribuir la variación de sentimiento en los tweets.
6.	 Cambiar a hipótesis, cambia la percepción de las personas a partir de marzo 
¿Se puede generar un clasificador que se pueda generalizar en base a los datos que tenemos?

La pregunta será reemplazada por la siguiente hipótesis:

Los sentimientos de una nueva base de datos pueden ser definidos a partir de un clasificador entrenado con una base de datos previa.

La metodologia a usar para comprobar esta hipótesis se describe en el capitulo propuesta experimental.

7.	¿El sentimiento de los comentarios se ha visto modificado con respecto a tiempos anteriores al Covid?
No es posible encontrar una base de datos, previa a la pandemia, que sirva como comparación al problema que se aborda en el presente análisis; por lo tanto, esta pregunta no se responderá. 


# Propuesta experimental

Con el fin de responder las preguntas e hipótesis que quedan por evaluar, se propone seguir la metodología.
•	En el data set inicial existen ubicaciones desde donde se escribieron los Tweets descritas por ciudad, para el proyecto las ubicaciones deben ser dadas por país, así que se estandarizó este atributo de manera de poder interpretar la información. También se eliminaron hashtags, pues no son considerados en el análisis de sentimiento.
•	Se extraerá características del texto de los tweets representándolo de forma vectorial para relacionarlo con el sentimiento que se le ha asignado de forma manual.
•	Se dividirá la base de datos en dos grupo set de entrenamiento y set de evaluación, con un porcentaje de 80% y 20% respectivamente .
•	Para definir el modelo que arroja una mejor clasificación se evaluará la base de datos usando Naive Bayes, Arboles de desicion, K_Mean y SVM. Se asignaran hiperparametros de evaluación a cada uno de los modelos a usar.
•	Los resultados obtenidos al aplicar los diferentes modelos se comparar usando métricas tradicionales F1, precision y recall, además aplicando validación cruzada sobre los grupos  cross validation sobre lo grupos de entrenamiento  y testeo respectivamente. 
•	Después de elegir el modelo que mejor clasifica los datos, se usará para asignar sentimiento a una base de datos nueva que será limpiada y estandarizada según los atributos de la base de dato inicial.
•	Se agrupará la asignación de sentimiento de la base de datos nueva según ubicación y se comparará con la base de datos inicial, para así identificar si existe alguna tendencia.  


# Referencias

[1] Twitter suma 166 millones de usuarios durante el Coronavirus. (2020, 3 junio). REBOLD, Data-Driven Marketing & Communication. https://letsrebold.com/es/blog/twitter-suma-166-millones-de-usuarios-frente-al-coronavirus/#:%7E:text=Asimismo%2C%20Twitter%20comunic%C3%B3%20en%20la,el%20primer%20trimestre%20de%202019.

[2] Coronavirus tweets NLP - Text Classification. (2020, 8 septiembre). Kaggle. https://www.kaggle.com/datatattle/covid-19-nlp-text-classification?select=Corona_NLP_test.csv


# Contribuciones del equipo
Existen tareas que fueron realizadas en conjunto por el grupo, tales como la selección del tema de interés y la búsqueda de bases de datos que se ajustarán a los requerimientos del grupo. A continuación se detallan las tareas que realizó cada miembro del equipo:

1. Nicolás Herrera: Construcción de presentación, grabación, edición del vídeo, construcción de tablas y análisis de los datos.

2. Yesenia Marulanda: Redacción de introducción, motivación e hipótesis del trabajo y construcción de presentación.

3. Franco Migliorelli: Redacción de introducción, motivación y análisis de gráficos generados, además de redacción de próximos pasos.

4. Samuel Sánchez: Análisis de gráficos, tratamiento de datos y redacción de hipótesis y preguntas.

5. Sebastián Urbina: Creación de gráficos, limpieza y tratamientos de datos.

